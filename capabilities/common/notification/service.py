"""
APG Notification Capability - Core Service Layer

Comprehensive notification service providing enterprise-grade notification management
with AI-powered personalization, universal channel orchestration, real-time delivery,
and advanced analytics integration.

Copyright Â© 2025 Datacraft
Author: Nyimbi Odero <nyimbi@gmail.com>
Website: www.datacraft.co.ke
"""

import asyncio
import json
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from contextlib import asynccontextmanager
from uuid_extensions import uuid7str

# SQLAlchemy models
from .models import (
	NENotification, NETemplate, NEDelivery, NEInteraction, NECampaign,
	NECampaignStep, NEUserPreference, NEProvider
)

# Pydantic API models
from .api_models import (
	DeliveryRequest, ComprehensiveDelivery, UltimateNotificationTemplate,
	AdvancedCampaign, UltimateUserPreferences, EngagementMetrics,
	UltimateAnalytics, DeliveryChannel, NotificationPriority,
	EngagementEvent, ConversionEvent, ApiResponse
)


# Configure logging
_log = logging.getLogger(__name__)


@dataclass
class NotificationServiceConfig:
	"""Configuration for notification service"""
	tenant_id: str
	max_concurrent_deliveries: int = 100
	delivery_timeout_seconds: int = 30
	retry_attempts: int = 3
	batch_size: int = 1000
	enable_personalization: bool = True
	enable_analytics: bool = True
	enable_geofencing: bool = False
	default_priority: NotificationPriority = NotificationPriority.NORMAL


class NotificationService:
	"""
	Core notification service providing comprehensive notification management
	with AI-powered personalization, universal channel orchestration, and analytics.
	"""
	
	def __init__(self, config: NotificationServiceConfig):
		"""Initialize notification service with configuration"""
		self.config = config
		self.tenant_id = config.tenant_id
		
		# Initialize service components (would be injected in real implementation)
		self._channel_manager = None  # UniversalChannelManager
		self._personalization_engine = None  # IntelligentPersonalizationEngine
		self._analytics_engine = None  # AnalyticsEngine
		self._delivery_engine = None  # RealTimeDeliveryEngine
		self._geofencing_engine = None  # GeofencingEngine
		
		# Performance tracking
		self._delivery_stats = {
			'total_sent': 0,
			'total_delivered': 0,
			'total_failed': 0,
			'average_latency_ms': 0
		}
		
		_log.info(f"NotificationService initialized for tenant {self.tenant_id}")
	
	# ========== Core Notification Operations ==========
	
	async def send_notification(
		self,
		request: DeliveryRequest,
		context: Optional[Dict[str, Any]] = None
	) -> ComprehensiveDelivery:
		"""
		Send individual notification with full orchestration and tracking.
		
		Args:
			request: Notification delivery request
			context: Additional context for personalization and analytics
		
		Returns:
			Complete delivery tracking record
		"""
		_log.info(f"Processing notification delivery for recipient {request.recipient_id}")
		
		try:
			# Create delivery record
			delivery = ComprehensiveDelivery(
				tenant_id=self.tenant_id,
				recipient_id=request.recipient_id,
				template_id=request.template_id,
				channels=request.channels,
				priority=request.priority
			)
			
			# Get user preferences for personalization
			user_preferences = await self._get_user_preferences(request.recipient_id)
			
			# Apply personalization if enabled
			if request.personalization_enabled and self._personalization_engine:
				personalized_content = await self._personalization_engine.personalize_content(
					template_id=request.template_id,
					user_id=request.recipient_id,
					variables=request.variables,
					context=context or {}
				)
				delivery.personalized_content = personalized_content
			
			# Optimize channel selection based on user preferences and engagement history
			optimized_channels = await self._optimize_channel_selection(
				request.channels,
				user_preferences,
				request.priority
			)
			
			# Execute delivery across channels
			delivery_start = datetime.utcnow()
			delivery_results = await self._execute_multi_channel_delivery(
				delivery,
				optimized_channels,
				request
			)
			
			# Calculate performance metrics
			delivery_end = datetime.utcnow()
			delivery.delivery_latency_ms = int((delivery_end - delivery_start).total_seconds() * 1000)
			
			# Update delivery record with results
			delivery.successful_channels = [
				result['channel'] for result in delivery_results if result['success']
			]
			delivery.failed_channels = [
				result['channel'] for result in delivery_results if not result['success']
			]
			
			# Determine overall status
			if delivery.successful_channels:
				delivery.status = "delivered" if len(delivery.successful_channels) == len(request.channels) else "partial"
				delivery.delivered_at = datetime.utcnow()
			else:
				delivery.status = "failed"
			
			# Track analytics if enabled
			if request.tracking_enabled and self._analytics_engine:
				await self._analytics_engine.track_delivery(delivery)
			
			# Update service statistics
			self._update_delivery_stats(delivery)
			
			_log.info(f"Notification delivery completed: {delivery.status} for {request.recipient_id}")
			return delivery
			
		except Exception as e:
			_log.error(f"Failed to send notification: {str(e)}")
			# Create failed delivery record
			failed_delivery = ComprehensiveDelivery(
				tenant_id=self.tenant_id,
				recipient_id=request.recipient_id,
				template_id=request.template_id,
				channels=request.channels,
				priority=request.priority,
				status="failed",
				failed_channels=request.channels
			)
			return failed_delivery
	
	async def send_bulk_notifications(
		self,
		requests: List[DeliveryRequest],
		batch_size: Optional[int] = None
	) -> List[ComprehensiveDelivery]:
		"""
		Send bulk notifications with batching and optimization.
		
		Args:
			requests: List of delivery requests
			batch_size: Override default batch size
		
		Returns:
			List of delivery records
		"""
		batch_size = batch_size or self.config.batch_size
		_log.info(f"Processing bulk delivery: {len(requests)} notifications in batches of {batch_size}")
		
		results = []
		
		# Process in batches to avoid overwhelming the system
		for i in range(0, len(requests), batch_size):
			batch = requests[i:i + batch_size]
			_log.debug(f"Processing batch {i//batch_size + 1}: {len(batch)} notifications")
			
			# Process batch concurrently with semaphore to limit concurrency
			semaphore = asyncio.Semaphore(self.config.max_concurrent_deliveries)
			
			async def process_with_semaphore(request):
				async with semaphore:
					return await self.send_notification(request)
			
			# Execute batch concurrently
			batch_results = await asyncio.gather(
				*[process_with_semaphore(req) for req in batch],
				return_exceptions=True
			)
			
			# Handle any exceptions in batch
			for j, result in enumerate(batch_results):
				if isinstance(result, Exception):
					_log.error(f"Batch delivery failed for request {i+j}: {result}")
					# Create failed delivery record
					failed_delivery = ComprehensiveDelivery(
						tenant_id=self.tenant_id,
						recipient_id=batch[j].recipient_id,
						template_id=batch[j].template_id,
						channels=batch[j].channels,
						priority=batch[j].priority,
						status="failed"
					)
					results.append(failed_delivery)
				else:
					results.append(result)
		
		_log.info(f"Bulk delivery completed: {len(results)} notifications processed")
		return results
	
	# ========== Campaign Management ==========
	
	async def execute_campaign(
		self,
		campaign: AdvancedCampaign,
		execute_immediately: bool = False
	) -> Dict[str, Any]:
		"""
		Execute notification campaign with full orchestration.
		
		Args:
			campaign: Campaign configuration
			execute_immediately: Override scheduling and execute now
		
		Returns:
			Campaign execution results
		"""
		_log.info(f"Executing campaign: {campaign.name} (ID: {campaign.id})")
		
		try:
			# Check if campaign should execute now
			if not execute_immediately and campaign.scheduled_at:
				if datetime.utcnow() < campaign.scheduled_at:
					_log.info(f"Campaign {campaign.id} scheduled for future execution")
					return {
						'status': 'scheduled',
						'message': f'Campaign scheduled for {campaign.scheduled_at}',
						'execution_time': campaign.scheduled_at
					}
			
			# Build audience from segments
			audience = await self._build_campaign_audience(campaign.audience_segments)
			if not audience:
				_log.warning(f"No audience found for campaign {campaign.id}")
				return {
					'status': 'failed',
					'message': 'No recipients found for campaign',
					'total_recipients': 0
				}
			
			# Create delivery requests for each recipient and template combination
			delivery_requests = []
			for recipient in audience:
				for template_id in campaign.template_ids:
					request = DeliveryRequest(
						recipient_id=recipient['user_id'],
						template_id=template_id,
						channels=campaign.channels,
						priority=campaign.priority,
						campaign_id=campaign.id,
						personalization_enabled=True,
						tracking_enabled=campaign.tracking_enabled
					)
					delivery_requests.append(request)
			
			_log.info(f"Campaign {campaign.id}: {len(delivery_requests)} deliveries to execute")
			
			# Execute deliveries
			execution_start = datetime.utcnow()
			delivery_results = await self.send_bulk_notifications(delivery_requests)
			execution_end = datetime.utcnow()
			
			# Calculate campaign metrics
			successful_deliveries = [d for d in delivery_results if d.status in ['delivered', 'partial']]
			failed_deliveries = [d for d in delivery_results if d.status == 'failed']
			
			execution_results = {
				'status': 'completed',
				'campaign_id': campaign.id,
				'execution_time': execution_start,
				'duration_seconds': (execution_end - execution_start).total_seconds(),
				'total_recipients': len(audience),
				'total_deliveries': len(delivery_requests),
				'successful_deliveries': len(successful_deliveries),
				'failed_deliveries': len(failed_deliveries),
				'success_rate': (len(successful_deliveries) / len(delivery_results)) * 100 if delivery_results else 0,
				'channel_breakdown': self._calculate_channel_breakdown(delivery_results),
				'delivery_results': delivery_results
			}
			
			# Update campaign analytics if enabled
			if self._analytics_engine:
				await self._analytics_engine.track_campaign_execution(campaign, execution_results)
			
			_log.info(f"Campaign {campaign.id} execution completed: {execution_results['success_rate']:.1f}% success rate")
			return execution_results
			
		except Exception as e:
			_log.error(f"Campaign execution failed: {str(e)}")
			return {
				'status': 'failed',
				'message': f'Campaign execution failed: {str(e)}',
				'error': str(e)
			}
	
	# ========== Analytics and Reporting ==========
	
	async def get_delivery_analytics(
		self,
		period_start: datetime,
		period_end: datetime,
		campaign_id: Optional[str] = None,
		channel_filter: Optional[List[DeliveryChannel]] = None
	) -> UltimateAnalytics:
		"""
		Get comprehensive analytics for notifications in specified period.
		
		Args:
			period_start: Analysis period start
			period_end: Analysis period end  
			campaign_id: Optional campaign filter
			channel_filter: Optional channel filter
		
		Returns:
			Complete analytics report
		"""
		_log.info(f"Generating analytics report for period {period_start} to {period_end}")
		
		try:
			# This would query the database for actual metrics
			# For now, returning mock data structure
			
			base_metrics = EngagementMetrics(
				total_sent=10000,
				total_delivered=9800,
				total_opened=2450,
				total_clicked=490,
				total_converted=98,
				delivery_rate=98.0,
				open_rate=25.0,
				click_rate=20.0,
				conversion_rate=2.0,
				engagement_score=75.5
			)
			
			analytics = UltimateAnalytics(
				period_start=period_start,
				period_end=period_end,
				engagement_metrics=base_metrics,
				campaign_id=campaign_id,
				campaign_performance={
					'total_campaigns': 15,
					'active_campaigns': 8,
					'top_performing_campaign': 'welcome_series_v2',
					'avg_campaign_roi': 285.5
				},
				audience_insights={
					'total_users': 12500,
					'active_users': 8900,
					'high_engagement_users': 2100,
					'churn_risk_users': 450
				},
				predictive_insights={
					'next_period_forecast': {
						'expected_deliveries': 12500,
						'predicted_engagement_rate': 26.2,
						'roi_projection': 315.8
					},
					'optimization_opportunities': [
						'Increase email frequency for high-engagement segments',
						'Test SMS for mobile-active users',
						'Personalize content for low-engagement users'
					]
				},
				geographic_breakdown={
					'top_regions': ['North America', 'Europe', 'Asia-Pacific'],
					'engagement_by_region': {
						'North America': 28.5,
						'Europe': 23.2,
						'Asia-Pacific': 21.8
					}
				},
				optimization_suggestions=[
					{
						'type': 'send_time_optimization',
						'impact': 'high',
						'description': 'Optimize send times based on user timezone and behavior',
						'expected_lift': '15-25%'
					},
					{
						'type': 'channel_optimization',
						'impact': 'medium',
						'description': 'Test push notifications for mobile-active users',
						'expected_lift': '8-15%'
					}
				]
			)
			
			return analytics
			
		except Exception as e:
			_log.error(f"Failed to generate analytics: {str(e)}")
			raise
	
	async def track_engagement_event(
		self,
		delivery_id: str,
		event_type: EngagementEvent,
		event_data: Optional[Dict[str, Any]] = None
	) -> bool:
		"""
		Track user engagement event for analytics.
		
		Args:
			delivery_id: Delivery record ID
			event_type: Type of engagement event
			event_data: Additional event context
		
		Returns:
			Success status
		"""
		_log.debug(f"Tracking engagement event: {event_type} for delivery {delivery_id}")
		
		try:
			# This would update the database with engagement data
			# and trigger real-time analytics updates
			
			if self._analytics_engine:
				await self._analytics_engine.track_engagement(
					delivery_id=delivery_id,
					event_type=event_type,
					event_data=event_data or {},
					timestamp=datetime.utcnow()
				)
			
			return True
			
		except Exception as e:
			_log.error(f"Failed to track engagement event: {str(e)}")
			return False
	
	# ========== User Preference Management ==========
	
	async def get_user_preferences(
		self,
		user_id: str
	) -> Optional[UltimateUserPreferences]:
		"""Get comprehensive user notification preferences."""
		return await self._get_user_preferences(user_id)
	
	async def update_user_preferences(
		self,
		user_id: str,
		preferences: UltimateUserPreferences
	) -> bool:
		"""
		Update user notification preferences.
		
		Args:
			user_id: User ID
			preferences: Updated preferences
		
		Returns:
			Success status
		"""
		_log.info(f"Updating preferences for user {user_id}")
		
		try:
			# This would update the database with new preferences
			# In real implementation, would validate and save to NEUserPreference model
			
			# Trigger preference change analytics
			if self._analytics_engine:
				await self._analytics_engine.track_preference_change(
					user_id=user_id,
					changes=preferences.model_dump(),
					timestamp=datetime.utcnow()
				)
			
			_log.info(f"Preferences updated successfully for user {user_id}")
			return True
			
		except Exception as e:
			_log.error(f"Failed to update user preferences: {str(e)}")
			return False
	
	# ========== Service Management ==========
	
	async def get_service_health(self) -> Dict[str, Any]:
		"""Get comprehensive service health status."""
		return {
			'status': 'healthy',
			'tenant_id': self.tenant_id,
			'version': '1.0.0',
			'uptime_seconds': 3600,  # Would calculate actual uptime
			'delivery_stats': self._delivery_stats,
			'component_status': {
				'channel_manager': 'healthy' if self._channel_manager else 'not_initialized',
				'personalization_engine': 'healthy' if self._personalization_engine else 'not_initialized',
				'analytics_engine': 'healthy' if self._analytics_engine else 'not_initialized',
				'delivery_engine': 'healthy' if self._delivery_engine else 'not_initialized'
			},
			'performance_metrics': {
				'avg_delivery_latency_ms': self._delivery_stats.get('average_latency_ms', 0),
				'current_queue_size': 0,  # Would get from actual queue
				'throughput_per_hour': 0  # Would calculate from recent deliveries
			}
		}
	
	# ========== Private Helper Methods ==========
	
	async def _get_user_preferences(
		self,
		user_id: str
	) -> Optional[UltimateUserPreferences]:
		"""Get user preferences from database or create defaults."""
		try:
			# This would query NEUserPreference model
			# For now, return default preferences
			return UltimateUserPreferences(
				user_id=user_id,
				tenant_id=self.tenant_id,
				personalization_enabled=True,
				engagement_score=75.0
			)
		except Exception as e:
			_log.error(f"Failed to get user preferences: {str(e)}")
			return None
	
	async def _optimize_channel_selection(
		self,
		requested_channels: List[DeliveryChannel],
		user_preferences: Optional[UltimateUserPreferences],
		priority: NotificationPriority
	) -> List[DeliveryChannel]:
		"""Optimize channel selection based on preferences and priority."""
		if not user_preferences:
			return requested_channels
		
		# Apply user channel preferences
		optimized_channels = []
		for channel in requested_channels:
			if channel in user_preferences.channel_preferences:
				channel_pref = user_preferences.channel_preferences[channel]
				if channel_pref.enabled:
					optimized_channels.append(channel)
			else:
				# Default to enabled if no specific preference
				optimized_channels.append(channel)
		
		# For high priority notifications, ensure at least one channel
		if priority in [NotificationPriority.HIGH, NotificationPriority.URGENT, NotificationPriority.CRITICAL]:
			if not optimized_channels and requested_channels:
				optimized_channels = [requested_channels[0]]  # Use first requested channel
		
		return optimized_channels or requested_channels
	
	async def _execute_multi_channel_delivery(
		self,
		delivery: ComprehensiveDelivery,
		channels: List[DeliveryChannel],
		request: DeliveryRequest
	) -> List[Dict[str, Any]]:
		"""Execute delivery across multiple channels."""
		results = []
		
		for channel in channels:
			try:
				# This would use the channel manager to send via specific channel
				# For now, simulate success/failure based on channel priority
				success = True  # Would be actual delivery result
				
				result = {
					'channel': channel,
					'success': success,
					'provider': f'{channel.value}_provider',
					'delivery_time_ms': 150,  # Would be actual delivery time
					'cost': 0.001 if channel == DeliveryChannel.SMS else 0.0001
				}
				
				results.append(result)
				
			except Exception as e:
				_log.error(f"Channel delivery failed for {channel}: {str(e)}")
				results.append({
					'channel': channel,
					'success': False,
					'error': str(e),
					'delivery_time_ms': 0,
					'cost': 0
				})
		
		return results
	
	async def _build_campaign_audience(
		self,
		audience_segments: List[Dict[str, Any]]
	) -> List[Dict[str, Any]]:
		"""Build campaign audience from segment definitions."""
		# This would query users based on segment criteria
		# For now, return mock audience
		return [
			{'user_id': f'user_{i}', 'email': f'user{i}@example.com'}
			for i in range(1, 101)  # Mock 100 users
		]
	
	def _calculate_channel_breakdown(
		self,
		delivery_results: List[ComprehensiveDelivery]
	) -> Dict[str, Dict[str, int]]:
		"""Calculate delivery breakdown by channel."""
		breakdown = {}
		
		for delivery in delivery_results:
			for channel in delivery.channels:
				if channel.value not in breakdown:
					breakdown[channel.value] = {'sent': 0, 'delivered': 0, 'failed': 0}
				
				breakdown[channel.value]['sent'] += 1
				
				if channel in delivery.successful_channels:
					breakdown[channel.value]['delivered'] += 1
				elif channel in delivery.failed_channels:
					breakdown[channel.value]['failed'] += 1
		
		return breakdown
	
	def _update_delivery_stats(self, delivery: ComprehensiveDelivery) -> None:
		"""Update service delivery statistics."""
		self._delivery_stats['total_sent'] += 1
		
		if delivery.status in ['delivered', 'partial']:
			self._delivery_stats['total_delivered'] += 1
		else:
			self._delivery_stats['total_failed'] += 1
		
		# Update average latency (simple moving average)
		if delivery.delivery_latency_ms:
			current_avg = self._delivery_stats['average_latency_ms']
			total_sent = self._delivery_stats['total_sent']
			self._delivery_stats['average_latency_ms'] = (
				(current_avg * (total_sent - 1) + delivery.delivery_latency_ms) / total_sent
			)


# Factory function for service creation
def create_notification_service(tenant_id: str, **config_overrides) -> NotificationService:
	"""
	Create notification service instance with configuration.
	
	Args:
		tenant_id: Tenant ID for multi-tenant isolation
		**config_overrides: Configuration overrides
	
	Returns:
		Configured notification service instance
	"""
	config = NotificationServiceConfig(
		tenant_id=tenant_id,
		**config_overrides
	)
	
	return NotificationService(config)


# Context manager for service lifecycle
@asynccontextmanager
async def notification_service_context(tenant_id: str, **config_overrides):
	"""
	Async context manager for notification service lifecycle.
	
	Usage:
		async with notification_service_context('tenant_123') as service:
			await service.send_notification(request)
	"""
	service = create_notification_service(tenant_id, **config_overrides)
	try:
		# Initialize service components
		_log.info(f"Initializing notification service for tenant {tenant_id}")
		yield service
	finally:
		# Cleanup service resources
		_log.info(f"Cleaning up notification service for tenant {tenant_id}")


# Export main classes and functions
__all__ = [
	'NotificationService',
	'NotificationServiceConfig', 
	'create_notification_service',
	'notification_service_context'
]